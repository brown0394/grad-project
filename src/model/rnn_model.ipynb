{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sector_id</th>\n",
       "      <th># of blocks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.652817</td>\n",
       "      <td>7487488</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.652824</td>\n",
       "      <td>7489536</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.652830</td>\n",
       "      <td>7491584</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.652836</td>\n",
       "      <td>7493632</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.652842</td>\n",
       "      <td>7495680</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  sector_id  # of blocks\n",
       "0   1.652817    7487488         2048\n",
       "1   1.652824    7489536         2048\n",
       "2   1.652830    7491584         2048\n",
       "3   1.652836    7493632         2048\n",
       "4   1.652842    7495680         2048"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData = pd.read_csv('../../data/trainData.csv', header=None)\n",
    "# AATI = Average Access Time Interval\n",
    "trainingData.columns = [\"timestamp\", \"sector_id\", \"# of blocks\"]\n",
    "trainingData.head()\n",
    "\n",
    "# trainingData.Frequency.hist(bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   timestamp  sector_id  # of blocks\n",
      "0   0.000000     303567            7\n",
      "1   0.000000      55590            6\n",
      "2   0.026214     303574            7\n",
      "3   0.026214     240840            6\n",
      "4   0.117964     303581            7\n"
     ]
    }
   ],
   "source": [
    "testData = pd.read_csv(\"../../data/testData.csv\", header=None)\n",
    "testData.columns = [\"timestamp\", \"sector_id\", \"# of blocks\"]\n",
    "testData.head()\n",
    "\n",
    "print(testData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sector_id  frequency      AATI  # of blocks  hot/cold\n",
      "0     753921      90736  0.459198       544416         1\n",
      "1     240840      48735  0.886414       292465         1\n",
      "2     836706      31787  1.296780       195293         1\n",
      "3     837306      31704  1.299350       192217         1\n",
      "4     700132      31288  1.156710       247313         1\n"
     ]
    }
   ],
   "source": [
    "testDataLabel = pd.read_csv(\"../../data/lableing/testDataLabeled.csv\", header=None)\n",
    "testDataLabel.columns = [\"sector_id\", \"frequency\", \"AATI\", \"# of blocks\",\"hot/cold\"]\n",
    "print(testDataLabel.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sector_id  frequency     AATI  # of blocks  hot/cold\n",
      "0       8488        966  36.0808         7728         1\n",
      "1     205888        948  36.7295         7584         1\n",
      "2     206064        948  36.7666         7584         1\n",
      "3      74328        947  36.7683         7576         1\n",
      "4      74408        945  36.8834         7560         1\n"
     ]
    }
   ],
   "source": [
    "trainDataLabel = pd.read_csv(\"../../data/lableing/trainDataLabeled.csv\", header=None)\n",
    "trainDataLabel.columns = [\"sector_id\", \"frequency\", \"AATI\", \"# of blocks\",\"hot/cold\"]\n",
    "print(trainDataLabel.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainDataLabel size: 1586700\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "trainLabelSize = trainDataLabel[\"sector_id\"].size\n",
    "print(\"trainDataLabel size:\", trainLabelSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sector_id        int64\n",
       "frequency        int64\n",
       "AATI           float64\n",
       "# of blocks      int64\n",
       "hot/cold         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataLabel.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp      float64\n",
       "sector_id        int64\n",
       "# of blocks      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingYLabelMap = {}\n",
    "\n",
    "for i in range(trainLabelSize):\n",
    "    trainingYLabelMap[trainDataLabel[\"sector_id\"][i]] = trainDataLabel[\"hot/cold\"][i]\n",
    "\n",
    "trainingData[\"hot/cold\"] = [trainingYLabelMap[sectorId] if sectorId in trainingYLabelMap else np.nan for sectorId in trainingData[\"sector_id\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testLabelSize = testDataLabel[\"sector_id\"].size\n",
    "testYLabelMap = {}\n",
    "\n",
    "for i in range(testLabelSize):\n",
    "    testYLabelMap[testDataLabel[\"sector_id\"][i]] = testDataLabel[\"hot/cold\"][i]\n",
    "\n",
    "testData[\"hot/cold\"] = [testYLabelMap[sectorId] if sectorId in testYLabelMap else np.nan for sectorId in testData[\"sector_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not np.any(np.isnan())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not np.any(np.isnan(testData[\"hot/cold\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1354099\n",
       "1     232601\n",
       "Name: hot/cold, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataLabel[\"hot/cold\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6057980\n",
       "0    3628281\n",
       "Name: hot/cold, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData[\"hot/cold\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2070048\n",
       "0    2029306\n",
       "Name: hot/cold, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData[\"hot/cold\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing number of blocks\n",
    "trainBlocksMean = trainingData[\"# of blocks\"].mean()\n",
    "trainBlocksStd = trainingData[\"# of blocks\"].std()\n",
    "\n",
    "trainingData[\"# of blocks\"] = (trainingData[\"# of blocks\"] - trainBlocksMean) / trainBlocksStd\n",
    "\n",
    "testBlocksMean = testData[\"# of blocks\"].mean()\n",
    "testBlocksStd = testData[\"# of blocks\"].std()\n",
    "\n",
    "testData[\"# of blocks\"] = (testData[\"# of blocks\"] - testBlocksMean) / testBlocksStd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try univariate LSTM first\n",
    "features = trainingData[\"sector_id\"].to_numpy()\n",
    "target = trainingData[[\"hot/cold\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFeatures = testData[\"sector_id\"].to_numpy().tolist()\n",
    "testTarget = testData[\"hot/cold\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom window function\n",
    "def makeWindow(features, windowLength=1000, step=1):\n",
    "    res = []\n",
    "    i = 0\n",
    "    while len(features) - windowLength >= i:\n",
    "        res.append(features[i:i+windowLength])\n",
    "        i += step\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowedFeatures = makeWindow(features, windowLength=1000, step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([7487488, 7489536, 7491584, 7493632, 7495680, 7497728, 7499776,\n",
       "        7501824, 7503872, 7505920]),\n",
       " array([7497728, 7499776, 7501824, 7503872, 7505920, 7507968, 7510016,\n",
       "        7512064, 7514112, 7516160])]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windowedFeatures[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 16:45:19.570238: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-28 16:45:20.158676: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-07-28 16:45:21.786423: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-07-28 16:45:21.786585: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-07-28 16:45:21.786596: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 16:45:23.320503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 16:45:23.420546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 16:45:23.420881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 16:45:23.422297: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-28 16:45:23.422625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 16:45:23.422935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 16:45:23.423234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 16:45:24.594485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 16:45:24.595220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 16:45:24.595384: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 16:45:24.595523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3381 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 960M, pci bus id: 0000:02:00.0, compute capability: 5.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/skele/Documents/PNU/grad/grad-project/src/model/rnn_model.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/skele/Documents/PNU/grad/grad-project/src/model/rnn_model.ipynb#ch0000019?line=0'>1</a>\u001b[0m normalizationLayer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mNormalization(axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/skele/Documents/PNU/grad/grad-project/src/model/rnn_model.ipynb#ch0000019?line=1'>2</a>\u001b[0m normalizationLayer\u001b[39m.\u001b[39;49madapt(features)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/layers/preprocessing/normalization.py:286\u001b[0m, in \u001b[0;36mNormalization.adapt\u001b[0;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madapt\u001b[39m(\u001b[39mself\u001b[39m, data, batch_size\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, steps\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    241\u001b[0m     \u001b[39m\"\"\"Computes the mean and variance of values in a dataset.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \n\u001b[1;32m    243\u001b[0m \u001b[39m    Calling `adapt()` on a `Normalization` layer is an alternative to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39m          argument is not supported with array inputs.\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49madapt(data, batch_size\u001b[39m=\u001b[39;49mbatch_size, steps\u001b[39m=\u001b[39;49msteps)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/base_preprocessing_layer.py:257\u001b[0m, in \u001b[0;36mPreprocessingLayer.adapt\u001b[0;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mfor\u001b[39;00m _, iterator \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39menumerate_epochs():\n\u001b[1;32m    256\u001b[0m     \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m--> 257\u001b[0m         \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[1;32m    258\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapt_function(iterator)\n\u001b[1;32m    259\u001b[0m             \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/data_adapter.py:1374\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data:  \u001b[39m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[1;32m   1373\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1374\u001b[0m original_spe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution\u001b[39m.\u001b[39;49mnumpy()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m   1375\u001b[0m can_run_full_execution \u001b[39m=\u001b[39m (\n\u001b[1;32m   1376\u001b[0m     original_spe \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1377\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1378\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m original_spe\n\u001b[1;32m   1379\u001b[0m )\n\u001b[1;32m   1381\u001b[0m \u001b[39mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:637\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnumpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    636\u001b[0m   \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 637\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_value()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m    638\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    639\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:728\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    725\u001b[0m   value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_variable_op()\n\u001b[1;32m    726\u001b[0m \u001b[39m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[39m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[0;32m--> 728\u001b[0m \u001b[39mreturn\u001b[39;00m array_ops\u001b[39m.\u001b[39;49midentity(value)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:287\u001b[0m, in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Return a Tensor with the same shape and contents as input.\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \n\u001b[1;32m    253\u001b[0m \u001b[39mThe return value is not the same Tensor as the original, but contains the same\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39m  A `Tensor` or CompositeTensor. Has the same type and contents as `input`.\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[39m# Don't expand ResourceVariables, so identity(variable) will return a Tensor.\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39misinstance\u001b[39;49m(\u001b[39minput\u001b[39;49m, composite_tensor\u001b[39m.\u001b[39;49mCompositeTensor) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    288\u001b[0m     \u001b[39mnot\u001b[39;00m _pywrap_utils\u001b[39m.\u001b[39mIsResourceVariable(\u001b[39minput\u001b[39m)):\n\u001b[1;32m    289\u001b[0m   \u001b[39mreturn\u001b[39;00m nest\u001b[39m.\u001b[39mmap_structure(identity, \u001b[39minput\u001b[39m, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    290\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39minput\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mgraph\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    291\u001b[0m   \u001b[39m# Make sure we get an input with handle data attached from resource\u001b[39;00m\n\u001b[1;32m    292\u001b[0m   \u001b[39m# variables. Variables have correct handle data when graph building.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/abc.py:119\u001b[0m, in \u001b[0;36mABCMeta.__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__instancecheck__\u001b[39m(\u001b[39mcls\u001b[39m, instance):\n\u001b[1;32m    118\u001b[0m     \u001b[39m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m _abc_instancecheck(\u001b[39mcls\u001b[39;49m, instance)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "normalizationLayer = tf.keras.layers.Normalization(axis=None)\n",
    "normalizationLayer.adapt(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizedTrainInput = normalizationLayer(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: I basically concluded that large sector_ids are not possible to embed(preprocess).\n",
    "# However, I thought of a way to represent sector_ids in tensors and that is one hot encoding and deep neural networks (aka. Dense, Fully connected)\n",
    "# It could be wrong and I want more research on \n",
    "#   **representing numbers in one-hot encoding and RNN**\n",
    "#   **Is it possible to feed LSTM large numbers**\n",
    "# also checkout tf.data.Dataset.grouping_window() and tf.data.Dataset.window() functions \n",
    "# i think they can be used to generate windows. gl\n",
    "ds = tf.data.Dataset.from_tensor_slices((features, target))\n",
    "ds = ds.window(10, shift=1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operations on window\n",
    "count = 0\n",
    "\n",
    "def to_numpy(ds):\n",
    "    return list(ds.as_numpy_iterator())\n",
    "\n",
    "for window in ds:\n",
    "    if count == 5:\n",
    "        break\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxSectorNumber: 1000213824\n",
      "maxBlocks: 0.6759364762275851\n"
     ]
    }
   ],
   "source": [
    "maxSectorNumber = np.amax(trainingData[\"sector_id\"])\n",
    "maxBlocks = np.amax(trainingData[\"# of blocks\"])\n",
    "print(\"maxSectorNumber:\", maxSectorNumber)\n",
    "print(\"maxBlocks:\", maxBlocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addressToTensor(address):\n",
    "    addressSize = len(str(address)) \n",
    "    fill = [[0] * 10 for i in range(10 - addressSize)]\n",
    "    arr = [[1 if j == int(char) else 0 for j in range(10)] for i, char in enumerate(str(address))]\n",
    "\n",
    "    tensor = tf.Variable(fill + arr)\n",
    "    \n",
    "    return tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(10, 10) dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addressToTensor(10002138)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorTrainingData = []\n",
    "\n",
    "for i in range(10000):\n",
    "    tensorTrainingData.append(addressToTensor(features[i]))\n",
    "\n",
    "tensorTrainingData = tf.Variable(tensorTrainingData )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorTestData = []\n",
    "\n",
    "for i in range(10000):\n",
    "    tensorTestData.append(addressToTensor(testFeatures[i]))\n",
    "\n",
    "tensorTestData = tf.Variable(tensorTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 20:53:57.350907: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 774.76MiB (rounded to 812390400)requested by op StatelessRandomUniformV2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-07-28 20:53:57.350946: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] BFCAllocator dump for GPU_0_bfc\n",
      "2022-07-28 20:53:57.350962: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (256): \tTotal Chunks: 52, Chunks in use: 52. 13.0KiB allocated for chunks. 13.0KiB in use in bin. 1.3KiB client-requested in use in bin.\n",
      "2022-07-28 20:53:57.350987: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-28 20:53:57.350995: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1024): \tTotal Chunks: 5, Chunks in use: 5. 5.2KiB allocated for chunks. 5.2KiB in use in bin. 5.0KiB client-requested in use in bin.\n",
      "2022-07-28 20:53:57.351001: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-28 20:53:57.351007: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4096): \tTotal Chunks: 1, Chunks in use: 0. 5.8KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-28 20:53:57.351013: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-28 20:53:57.351018: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-28 20:53:57.351024: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-28 20:53:57.351031: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (65536): \tTotal Chunks: 9, Chunks in use: 9. 713.8KiB allocated for chunks. 713.8KiB in use in bin. 646.6KiB client-requested in use in bin.\n",
      "2022-07-28 20:53:57.351039: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (131072): \tTotal Chunks: 5, Chunks in use: 5. 640.2KiB allocated for chunks. 640.2KiB in use in bin. 590.1KiB client-requested in use in bin.\n",
      "2022-07-28 20:53:57.351044: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-28 20:53:57.351050: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-28 20:53:57.351056: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-28 20:53:57.351061: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-28 20:53:57.351084: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-28 20:53:57.351106: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-28 20:53:57.351112: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-28 20:53:57.351118: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-28 20:53:57.351124: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (67108864): \tTotal Chunks: 1, Chunks in use: 0. 73.00MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-28 20:53:57.351151: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 0. 207.95MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-28 20:53:57.351158: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (268435456): \tTotal Chunks: 4, Chunks in use: 4. 3.03GiB allocated for chunks. 3.03GiB in use in bin. 3.03GiB client-requested in use in bin.\n",
      "2022-07-28 20:53:57.351167: I tensorflow/core/common_runtime/bfc_allocator.cc:1056] Bin for 774.76MiB was 256.00MiB, Chunk State: \n",
      "2022-07-28 20:53:57.351172: I tensorflow/core/common_runtime/bfc_allocator.cc:1069] Next region of size 3545563136\n",
      "2022-07-28 20:53:57.351184: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec0000 of size 256 next 1\n",
      "2022-07-28 20:53:57.351192: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec0100 of size 1280 next 2\n",
      "2022-07-28 20:53:57.351201: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec0600 of size 256 next 40\n",
      "2022-07-28 20:53:57.351206: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec0700 of size 256 next 34\n",
      "2022-07-28 20:53:57.351211: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec0800 of size 256 next 42\n",
      "2022-07-28 20:53:57.351216: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec0900 of size 256 next 33\n",
      "2022-07-28 20:53:57.351222: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec0a00 of size 1024 next 41\n",
      "2022-07-28 20:53:57.351227: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec0e00 of size 256 next 44\n",
      "2022-07-28 20:53:57.351232: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec0f00 of size 256 next 45\n",
      "2022-07-28 20:53:57.351237: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec1000 of size 256 next 46\n",
      "2022-07-28 20:53:57.351242: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec1100 of size 256 next 47\n",
      "2022-07-28 20:53:57.351247: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec1200 of size 256 next 48\n",
      "2022-07-28 20:53:57.351252: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec1300 of size 256 next 49\n",
      "2022-07-28 20:53:57.351258: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec1400 of size 1024 next 52\n",
      "2022-07-28 20:53:57.351263: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec1800 of size 256 next 53\n",
      "2022-07-28 20:53:57.351267: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec1900 of size 256 next 54\n",
      "2022-07-28 20:53:57.351272: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec1a00 of size 1024 next 58\n",
      "2022-07-28 20:53:57.351277: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec1e00 of size 256 next 59\n",
      "2022-07-28 20:53:57.351281: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec1f00 of size 256 next 60\n",
      "2022-07-28 20:53:57.351286: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec2000 of size 256 next 61\n",
      "2022-07-28 20:53:57.351291: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec2100 of size 256 next 62\n",
      "2022-07-28 20:53:57.351296: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec2200 of size 256 next 63\n",
      "2022-07-28 20:53:57.351301: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec2300 of size 256 next 64\n",
      "2022-07-28 20:53:57.351306: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec2400 of size 256 next 65\n",
      "2022-07-28 20:53:57.351311: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec2500 of size 256 next 66\n",
      "2022-07-28 20:53:57.351315: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec2600 of size 256 next 67\n",
      "2022-07-28 20:53:57.351321: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec2700 of size 256 next 68\n",
      "2022-07-28 20:53:57.351326: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec2800 of size 256 next 69\n",
      "2022-07-28 20:53:57.351332: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec2900 of size 256 next 73\n",
      "2022-07-28 20:53:57.351337: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec2a00 of size 256 next 74\n",
      "2022-07-28 20:53:57.351342: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec2b00 of size 256 next 75\n",
      "2022-07-28 20:53:57.351347: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec2c00 of size 256 next 70\n",
      "2022-07-28 20:53:57.351352: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec2d00 of size 256 next 72\n",
      "2022-07-28 20:53:57.351357: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec2e00 of size 256 next 82\n",
      "2022-07-28 20:53:57.351362: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec2f00 of size 256 next 83\n",
      "2022-07-28 20:53:57.351367: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 701ec3000 of size 5888 next 35\n",
      "2022-07-28 20:53:57.351373: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec4700 of size 114944 next 36\n",
      "2022-07-28 20:53:57.351379: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ee0800 of size 131328 next 38\n",
      "2022-07-28 20:53:57.351385: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701f00900 of size 131072 next 39\n",
      "2022-07-28 20:53:57.351391: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701f20900 of size 80128 next 43\n",
      "2022-07-28 20:53:57.351396: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701f34200 of size 131072 next 50\n",
      "2022-07-28 20:53:57.351402: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701f54200 of size 65536 next 51\n",
      "2022-07-28 20:53:57.351407: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701f64200 of size 131072 next 56\n",
      "2022-07-28 20:53:57.351414: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701f84200 of size 65536 next 57\n",
      "2022-07-28 20:53:57.351420: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701f94200 of size 80128 next 77\n",
      "2022-07-28 20:53:57.351425: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 701fa7b00 of size 76542720 next 3\n",
      "2022-07-28 20:53:57.351430: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7068a6e00 of size 256 next 4\n",
      "2022-07-28 20:53:57.351435: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7068a6f00 of size 256 next 5\n",
      "2022-07-28 20:53:57.351440: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7068a7000 of size 256 next 16\n",
      "2022-07-28 20:53:57.351445: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7068a7100 of size 256 next 6\n",
      "2022-07-28 20:53:57.351451: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7068a7200 of size 256 next 8\n",
      "2022-07-28 20:53:57.351456: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7068a7300 of size 256 next 9\n",
      "2022-07-28 20:53:57.351462: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7068a7400 of size 256 next 13\n",
      "2022-07-28 20:53:57.351467: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7068a7500 of size 256 next 11\n",
      "2022-07-28 20:53:57.351472: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7068a7600 of size 256 next 18\n",
      "2022-07-28 20:53:57.351478: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7068a7700 of size 256 next 12\n",
      "2022-07-28 20:53:57.351483: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7068a7800 of size 256 next 15\n",
      "2022-07-28 20:53:57.351488: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7068a7900 of size 256 next 14\n",
      "2022-07-28 20:53:57.351493: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7068a7a00 of size 812390400 next 37\n",
      "2022-07-28 20:53:57.351499: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 736f69200 of size 812390400 next 17\n",
      "2022-07-28 20:53:57.351504: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 76762aa00 of size 812390400 next 10\n",
      "2022-07-28 20:53:57.351510: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 797cec200 of size 256 next 22\n",
      "2022-07-28 20:53:57.351514: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 797cec300 of size 256 next 7\n",
      "2022-07-28 20:53:57.351519: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 797cec400 of size 256 next 19\n",
      "2022-07-28 20:53:57.351524: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 797cec500 of size 256 next 23\n",
      "2022-07-28 20:53:57.351529: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 797cec600 of size 256 next 27\n",
      "2022-07-28 20:53:57.351534: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 797cec700 of size 256 next 24\n",
      "2022-07-28 20:53:57.351539: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 797cec800 of size 1024 next 26\n",
      "2022-07-28 20:53:57.351544: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 797cecc00 of size 256 next 28\n",
      "2022-07-28 20:53:57.351549: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 797cecd00 of size 256 next 29\n",
      "2022-07-28 20:53:57.351554: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 797cece00 of size 80128 next 30\n",
      "2022-07-28 20:53:57.351559: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 797d00700 of size 256 next 31\n",
      "2022-07-28 20:53:57.351564: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 797d00800 of size 80128 next 32\n",
      "2022-07-28 20:53:57.351569: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 797d14100 of size 98816 next 20\n",
      "2022-07-28 20:53:57.351574: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 797d2c300 of size 131072 next 21\n",
      "2022-07-28 20:53:57.351579: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 797d4c300 of size 65536 next 25\n",
      "2022-07-28 20:53:57.351585: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 797d5c300 of size 812390400 next 55\n",
      "2022-07-28 20:53:57.351590: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7c841db00 of size 218047744 next 18446744073709551615\n",
      "2022-07-28 20:53:57.351607: I tensorflow/core/common_runtime/bfc_allocator.cc:1094]      Summary of in-use Chunks by size: \n",
      "2022-07-28 20:53:57.351616: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 52 Chunks of size 256 totalling 13.0KiB\n",
      "2022-07-28 20:53:57.351622: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 4 Chunks of size 1024 totalling 4.0KiB\n",
      "2022-07-28 20:53:57.351629: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-07-28 20:53:57.351635: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 3 Chunks of size 65536 totalling 192.0KiB\n",
      "2022-07-28 20:53:57.351640: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 4 Chunks of size 80128 totalling 313.0KiB\n",
      "2022-07-28 20:53:57.351646: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 98816 totalling 96.5KiB\n",
      "2022-07-28 20:53:57.351652: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 114944 totalling 112.2KiB\n",
      "2022-07-28 20:53:57.351660: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 4 Chunks of size 131072 totalling 512.0KiB\n",
      "2022-07-28 20:53:57.351665: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 131328 totalling 128.2KiB\n",
      "2022-07-28 20:53:57.351671: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 4 Chunks of size 812390400 totalling 3.03GiB\n",
      "2022-07-28 20:53:57.351677: I tensorflow/core/common_runtime/bfc_allocator.cc:1101] Sum Total of in-use chunks: 3.03GiB\n",
      "2022-07-28 20:53:57.351682: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] total_region_allocated_bytes_: 3545563136 memory_limit_: 3545563136 available bytes: 0 curr_region_allocation_bytes_: 7091126272\n",
      "2022-07-28 20:53:57.351692: I tensorflow/core/common_runtime/bfc_allocator.cc:1109] Stats: \n",
      "Limit:                      3545563136\n",
      "InUse:                      3250966784\n",
      "MaxInUse:                   3251028992\n",
      "NumAllocs:                       93087\n",
      "MaxAllocSize:                812390400\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-07-28 20:53:57.351705: W tensorflow/core/common_runtime/bfc_allocator.cc:491] *_********************************************************************************************______\n",
      "2022-07-28 20:53:57.351731: W tensorflow/core/framework/op_kernel.cc:1777] OP_REQUIRES failed at stateless_random_ops_v2.cc:67 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[1586700,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[1586700,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessRandomUniformV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/home/skele/Documents/PNU/grad/grad-project/src/model/rnn_model.ipynb Cell 35\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/skele/Documents/PNU/grad/grad-project/src/model/rnn_model.ipynb#ch0000030?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mSequential()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/skele/Documents/PNU/grad/grad-project/src/model/rnn_model.ipynb#ch0000030?line=2'>3</a>\u001b[0m \u001b[39m# embedding the sector number from 0-1\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/skele/Documents/PNU/grad/grad-project/src/model/rnn_model.ipynb#ch0000030?line=3'>4</a>\u001b[0m \u001b[39m# input_shape=(number of time steps, number of features)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/skele/Documents/PNU/grad/grad-project/src/model/rnn_model.ipynb#ch0000030?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39;49madd(tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mEmbedding(input_dim\u001b[39m=\u001b[39;49mtrainLabelSize, output_dim\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, input_length\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/skele/Documents/PNU/grad/grad-project/src/model/rnn_model.ipynb#ch0000030?line=5'>6</a>\u001b[0m model\u001b[39m.\u001b[39madd(tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mLSTM(\u001b[39m64\u001b[39m,activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, input_shape\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m10\u001b[39m)))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/skele/Documents/PNU/grad/grad-project/src/model/rnn_model.ipynb#ch0000030?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39madd(tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDropout(\u001b[39m0.1\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/backend.py:2100\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[0;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[39mif\u001b[39;00m nonce:\n\u001b[1;32m   2099\u001b[0m         seed \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[0;32m-> 2100\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mstateless_uniform(\n\u001b[1;32m   2101\u001b[0m         shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m   2102\u001b[0m         minval\u001b[39m=\u001b[39;49mminval,\n\u001b[1;32m   2103\u001b[0m         maxval\u001b[39m=\u001b[39;49mmaxval,\n\u001b[1;32m   2104\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   2105\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m   2106\u001b[0m     )\n\u001b[1;32m   2107\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(\n\u001b[1;32m   2108\u001b[0m     shape\u001b[39m=\u001b[39mshape,\n\u001b[1;32m   2109\u001b[0m     minval\u001b[39m=\u001b[39mminval,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2112\u001b[0m     seed\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_legacy_seed(),\n\u001b[1;32m   2113\u001b[0m )\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[1586700,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessRandomUniformV2]"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# embedding the sector number from 0-1\n",
    "# input_shape=(number of time steps, number of features)\n",
    "model.add(tf.keras.layers.Embedding(input_dim=trainLabelSize, output_dim=128, input_length=1000))\n",
    "model.add(tf.keras.layers.LSTM(64,activation='relu', input_shape=(10, 10)))\n",
    "model.add(tf.keras.layers.Dropout(0.1))\n",
    "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer \n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "model.compile(optimizer=opt, loss=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10000, 10, 10])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorTrainingData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoded shit\n",
    "train_x = np.asarray(tensorTrainingData)\n",
    "test_x = np.asarray(tensorTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7487488, 7489536, 7491584, 7493632, 7495680, 7497728, 7499776,\n",
       "       7501824, 7503872, 7505920])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/home/skele/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/skele/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/skele/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/skele/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/skele/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"/home/skele/.local/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/skele/.local/lib/python3.10/site-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/skele/.local/lib/python3.10/site-packages/keras/losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/skele/.local/lib/python3.10/site-packages/keras/losses.py\", line 2084, in sparse_categorical_crossentropy\n        return backend.sparse_categorical_crossentropy(\n    File \"/home/skele/.local/lib/python3.10/site-packages/keras/backend.py\", line 5586, in sparse_categorical_crossentropy\n        epsilon_ = _constant_to_tensor(epsilon(), output.dtype.base_dtype)\n    File \"/home/skele/.local/lib/python3.10/site-packages/keras/backend.py\", line 985, in _constant_to_tensor\n        return tf.constant(x, dtype=dtype)\n\n    TypeError: Expected int64, but got 1e-07 of type 'float'.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/skele/Documents/PNU/grad/grad-project/src/model/rnn_model.ipynb Cell 40\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/skele/Documents/PNU/grad/grad-project/src/model/rnn_model.ipynb#ch0000034?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(features[:\u001b[39m10000\u001b[39;49m], target[:\u001b[39m10000\u001b[39;49m], epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileunka25h_.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/home/skele/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/skele/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/skele/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/skele/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/skele/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"/home/skele/.local/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/skele/.local/lib/python3.10/site-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/skele/.local/lib/python3.10/site-packages/keras/losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/skele/.local/lib/python3.10/site-packages/keras/losses.py\", line 2084, in sparse_categorical_crossentropy\n        return backend.sparse_categorical_crossentropy(\n    File \"/home/skele/.local/lib/python3.10/site-packages/keras/backend.py\", line 5586, in sparse_categorical_crossentropy\n        epsilon_ = _constant_to_tensor(epsilon(), output.dtype.base_dtype)\n    File \"/home/skele/.local/lib/python3.10/site-packages/keras/backend.py\", line 985, in _constant_to_tensor\n        return tf.constant(x, dtype=dtype)\n\n    TypeError: Expected int64, but got 1e-07 of type 'float'.\n"
     ]
    }
   ],
   "source": [
    "model.fit(features[:10000], target[:10000], epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model.predict(test_x, verbose=1)\n",
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(10000):\n",
    "    if y_hat[i] == testTarget[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(f\"Accuracy: {correct/10000}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan]], dtype=float32)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[0:100]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
