{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvzbTJ0c5l9S"
      },
      "source": [
        "### Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "c4OnWRBq5l9W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1EjfZSY-5l9Y",
        "outputId": "cd19efa4-9f8b-433f-b33d-295b60148c49"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>sector_id</th>\n",
              "      <th># of blocks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.652817</td>\n",
              "      <td>7487488</td>\n",
              "      <td>2048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.652824</td>\n",
              "      <td>7489536</td>\n",
              "      <td>2048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.652830</td>\n",
              "      <td>7491584</td>\n",
              "      <td>2048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.652836</td>\n",
              "      <td>7493632</td>\n",
              "      <td>2048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.652842</td>\n",
              "      <td>7495680</td>\n",
              "      <td>2048</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   timestamp  sector_id  # of blocks\n",
              "0   1.652817    7487488         2048\n",
              "1   1.652824    7489536         2048\n",
              "2   1.652830    7491584         2048\n",
              "3   1.652836    7493632         2048\n",
              "4   1.652842    7495680         2048"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainData = pd.read_csv('../../data/trainData.csv', header=None)\n",
        "# AATI = Average Access Time Interval\n",
        "trainData.columns = [\"timestamp\",\"sector_id\", \"# of blocks\"]\n",
        "trainData.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "btStFvlF5l9Z",
        "outputId": "ff0b9816-707c-4846-924a-f610e3dd8a81"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>sector_id</th>\n",
              "      <th># of blocks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>303567</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>55590</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.026214</td>\n",
              "      <td>303574</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.026214</td>\n",
              "      <td>240840</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.117964</td>\n",
              "      <td>303581</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   timestamp  sector_id  # of blocks\n",
              "0   0.000000     303567            7\n",
              "1   0.000000      55590            6\n",
              "2   0.026214     303574            7\n",
              "3   0.026214     240840            6\n",
              "4   0.117964     303581            7"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testData = pd.read_csv(\"../../data/testData.csv\", header=None)\n",
        "testData.columns = [\"timestamp\",\"sector_id\", \"# of blocks\"]\n",
        "testData.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEe_uMUM5l9a",
        "outputId": "dcb5f76f-0379-4262-ddca-379fbbeb7a27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   sector_id  frequency     AATI  time_interval_std  # of blocks  cluster\n",
            "0     753921      90736  0.45920        23941.33982       544416        1\n",
            "1     240840      48735  0.88641        24708.56721       292465        1\n",
            "2     836706      31787  1.29678        28796.58080       195293        1\n",
            "3     837306      31704  1.29935        28766.62024       192217        1\n",
            "4     700132      31288  1.15671        17203.72980       247313        3\n",
            "3    265152\n",
            "1    184942\n",
            "0    149575\n",
            "2    101204\n",
            "Name: cluster, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "testDataLabel = pd.read_csv(\"../../data/clustering/testDataClustered.csv\")\n",
        "testDataLabel.columns = [\"sector_id\", \"frequency\", \"AATI\", \"time_interval_std\",\"# of blocks\", \"cluster\"]\n",
        "print(testDataLabel.head())\n",
        "print(testDataLabel[\"cluster\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6JAL1O65l9a",
        "outputId": "e9b89822-fd1d-4a1e-d8a9-0f99ab3b6d0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   sector_id  frequency      AATI  time_interval_std  # of blocks  cluster\n",
            "0       8488        966  36.08076        20060.26401         7728        3\n",
            "1     205888        948  36.72951        20038.61273         7584        3\n",
            "2     206064        948  36.76656        19881.60064         7584        3\n",
            "3      74328        947  36.76833        20192.84732         7576        3\n",
            "4      74408        945  36.88340        20118.25940         7560        3\n",
            "0    697571\n",
            "1    324263\n",
            "3    322380\n",
            "2    242486\n",
            "Name: cluster, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "trainDataLabel = pd.read_csv(\"../../data/clustering/trainDataClustered.csv\")\n",
        "trainDataLabel.columns = [\"sector_id\", \"frequency\", \"AATI\", \"time_interval_std\",\"# of blocks\", \"cluster\"]\n",
        "print(trainDataLabel.head())\n",
        "print(trainDataLabel[\"cluster\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8j48oBXf5l9b",
        "outputId": "eff39dd2-f1cf-4d05-ec7e-bbb2f8c87e94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainDataLabel size: 1586700\n"
          ]
        }
      ],
      "source": [
        "# Constants\n",
        "trainLabelSize = trainDataLabel[\"sector_id\"].size\n",
        "print(\"trainDataLabel size:\", trainLabelSize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8r7tB9k5l9c",
        "outputId": "2d8814f3-2b9c-4e00-c9b1-394fb69491c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sector_id              int64\n",
              "frequency              int64\n",
              "AATI                 float64\n",
              "time_interval_std    float64\n",
              "# of blocks            int64\n",
              "cluster                int64\n",
              "dtype: object"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainDataLabel.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGItFiqi5l9d",
        "outputId": "9f3211a6-8fe7-4c71-8e4a-d271a68e20ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "timestamp      float64\n",
              "sector_id        int64\n",
              "# of blocks      int64\n",
              "dtype: object"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainData.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5-U1cChL5l9d"
      },
      "outputs": [],
      "source": [
        "trainingYLabelMap = {}\n",
        "\n",
        "# assuming cluster 3 is hot and others as cold\n",
        "for i in range(trainLabelSize):\n",
        "  if trainDataLabel[\"cluster\"][i] == 3:\n",
        "    trainingYLabelMap[trainDataLabel[\"sector_id\"][i]] = 1\n",
        "  else:\n",
        "    trainingYLabelMap[trainDataLabel[\"sector_id\"][i]] = 0\n",
        "\n",
        "trainData[\"hot/cold\"] = [trainingYLabelMap[sectorId] if sectorId in trainingYLabelMap else np.nan for sectorId in trainData[\"sector_id\"]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HtAIzQC35l9e"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/skele/Documents/PNU/grad/grad-project/src/model/multivar_lstm_model.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/skele/Documents/PNU/grad/grad-project/src/model/multivar_lstm_model.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# assuming cluster 1 as hot\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/skele/Documents/PNU/grad/grad-project/src/model/multivar_lstm_model.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(testLabelSize):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/skele/Documents/PNU/grad/grad-project/src/model/multivar_lstm_model.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m   \u001b[39mif\u001b[39;00m testDataLabel[\u001b[39m\"\u001b[39m\u001b[39mcluster\u001b[39m\u001b[39m\"\u001b[39m][i] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/skele/Documents/PNU/grad/grad-project/src/model/multivar_lstm_model.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     testYLabelMap[testDataLabel[\u001b[39m\"\u001b[39m\u001b[39msector_id\u001b[39m\u001b[39m\"\u001b[39m][i]] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/skele/Documents/PNU/grad/grad-project/src/model/multivar_lstm_model.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "testLabelSize = testDataLabel[\"sector_id\"].size\n",
        "testYLabelMap = {}\n",
        "    \n",
        "# assuming cluster 1 as hot\n",
        "for i in range(testLabelSize):\n",
        "  if testDataLabel[\"cluster\"][i] == 1:\n",
        "    testYLabelMap[testDataLabel[\"sector_id\"][i]] = 1\n",
        "  else:\n",
        "    testYLabelMap[testDataLabel[\"sector_id\"][i]] = 0\n",
        "\n",
        "testData[\"hot/cold\"] = [testYLabelMap[sectorId] if sectorId in testYLabelMap else np.nan for sectorId in testData[\"sector_id\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24eNGPO95l9f"
      },
      "outputs": [],
      "source": [
        "assert not np.any(np.isnan(testData[\"hot/cold\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l24ukler5l9f",
        "outputId": "80f30a4a-5387-4219-b3ea-ffb34c50c5c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    5544771\n",
              "0    4141490\n",
              "Name: hot/cold, dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainData[\"hot/cold\"].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu8SgUSY5l9g",
        "outputId": "04825249-2b69-49be-8ad2-df28b33ba503"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    2061887\n",
              "0    2037467\n",
              "Name: hot/cold, dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testData[\"hot/cold\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBqQVFCU5l9g"
      },
      "outputs": [],
      "source": [
        "# Normalizing number of blocks\n",
        "# trainBlocksMean = trainData[\"# of blocks\"].mean()\n",
        "# trainBlocksStd = trainData[\"# of blocks\"].std()\n",
        "\n",
        "# trainData[\"# of blocks\"] = (trainData[\"# of blocks\"] - trainBlocksMean) / trainBlocksStd\n",
        "\n",
        "# testBlocksMean = testData[\"# of blocks\"].mean()\n",
        "# testBlocksStd = testData[\"# of blocks\"].std()\n",
        "\n",
        "# testData[\"# of blocks\"] = (testData[\"# of blocks\"] - testBlocksMean) / testBlocksStd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wL41TZmz5l9k"
      },
      "outputs": [],
      "source": [
        "def addressToTensor(address):\n",
        "    addressSize = len(str(address)) \n",
        "    fill = [[0] * 10 for i in range(10 - addressSize)]\n",
        "    arr = [[1 if j == int(char) else 0 for j in range(10)] for i, char in enumerate(str(address))]\n",
        "\n",
        "    # tensor = tf.Variable(fill + arr)\n",
        "    # res = np.asarray(fill+arr)\n",
        "    return fill + arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6MqvyO9MSNg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "addressToTensor(1058376838)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibKKB975Akmp"
      },
      "outputs": [],
      "source": [
        "# def oneHotTrainData(rawData):\n",
        "#   count = 0\n",
        "#   oneHotList = [] \n",
        "#   for elem in rawData:\n",
        "#     oneHotList.append(addressToTensor(elem))\n",
        "  \n",
        "#   res = np.asarray(oneHotList)\n",
        "#   return res\n",
        "\n",
        "# v = np.vectorize(lambda row: addressToTensor(row))\n",
        "# windowTrain[\"sector_id\"] = v(windowTrain[\"sector_id\"])\n",
        "\n",
        "# windowTrain[\"sector_id\"] = windowTrain.apply(lambda row: addressToTensor(row[\"sector_id\"]), axis=1)\n",
        "# windowTrain.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA07LGbBNDHx"
      },
      "source": [
        "New feature for timestamp difference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dg9yAbBvNJBR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9686261\n"
          ]
        }
      ],
      "source": [
        "trainDataSize = trainData[\"sector_id\"].size\n",
        "print(trainDataSize)\n",
        "\n",
        "lastSectorEncounter = {}\n",
        "timeDelta = [0] * trainDataSize\n",
        "\n",
        "for i in range(trainDataSize):\n",
        "  sectorId = trainData[\"sector_id\"][i]\n",
        "  if sectorId in lastSectorEncounter:\n",
        "    timeDelta[i] = trainData[\"timestamp\"][i] - lastSectorEncounter[sectorId]\n",
        "  else:\n",
        "    timeDelta[i] = 0\n",
        "  lastSectorEncounter[sectorId] = trainData[\"timestamp\"][i]\n",
        "\n",
        "trainData[\"time_delta\"] = timeDelta\n",
        "# trainData[\"timestamp_delta\"] = [trainData[\"timestamp\"][i] - lastSectorEncounter if trainData[\"sector_id\"][i] in lastSectorEncounter else  for i in range(trainDataSize)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "testDataSize = testData[\"sector_id\"].size\n",
        "\n",
        "lastSectorEncounter = {}\n",
        "timeDelta = [0] * testDataSize\n",
        "\n",
        "for i in range(testDataSize):\n",
        "  sectorId = testData[\"sector_id\"][i]\n",
        "  if sectorId in lastSectorEncounter:\n",
        "    timeDelta[i] = testData[\"timestamp\"][i] - lastSectorEncounter[sectorId]\n",
        "  else:\n",
        "    timeDelta[i] = 0\n",
        "  lastSectorEncounter[sectorId] = testData[\"timestamp\"][i]\n",
        "\n",
        "testData[\"time_delta\"] = timeDelta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainDeltaMean = trainData[\"time_delta\"].mean()\n",
        "trainDeltaStd = trainData[\"time_delta\"].std()\n",
        "\n",
        "trainData[\"time_delta\"] = (trainData[\"time_delta\"] - trainDeltaMean) / trainDeltaStd\n",
        "\n",
        "testDeltaMean = testData[\"time_delta\"].mean()\n",
        "testDeltaStd = testData[\"time_delta\"].std()\n",
        "\n",
        "testData[\"time_delta\"] = (testData[\"time_delta\"] - testDeltaMean) / testDeltaStd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0   -0.391064\n",
              "1   -0.391064\n",
              "2   -0.391064\n",
              "3   -0.391064\n",
              "4   -0.391064\n",
              "Name: time_delta, dtype: float64"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainData[\"time_delta\"].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ed86jzkE42t"
      },
      "outputs": [],
      "source": [
        "windowTrain = trainData[[\"sector_id\",\"time_delta\", \"hot/cold\"]]\n",
        "windowTest = testData[[\"sector_id\",\"time_delta\", \"hot/cold\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNfw_yD-W4FV"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 256\n",
        "WINDOW_SIZE = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVMOuXUgOPxD"
      },
      "outputs": [],
      "source": [
        "class WindowGenerator():\n",
        "  def __init__(self, input_width, label_width, shift,\n",
        "               train_df=windowTrain,val_df=None, test_df=windowTest,\n",
        "               label_columns=None, input_columns=None):\n",
        "    # Store the raw data.\n",
        "    self.train_df = train_df\n",
        "    self.val_df = val_df\n",
        "    self.test_df = test_df\n",
        "\n",
        "    # Work out the label and input column indices.\n",
        "    self.label_columns = label_columns\n",
        "    self.input_columns = input_columns\n",
        "\n",
        "    if label_columns is not None:\n",
        "      self.label_columns_indices = {name: i for i, name in\n",
        "                                    enumerate(label_columns)}\n",
        "    if input_columns is not None:\n",
        "      self.input_columns_indices = {name: i for i, name in\n",
        "                                    enumerate(input_columns)}\n",
        "\n",
        "    self.column_indices = {name: i for i, name in\n",
        "                           enumerate(train_df.columns)}\n",
        "\n",
        "\n",
        "    # Work out the window parameters.\n",
        "    self.input_width = input_width\n",
        "    self.label_width = label_width\n",
        "    self.shift = shift\n",
        "\n",
        "    self.total_window_size = input_width + shift\n",
        "\n",
        "    self.input_slice = slice(0, input_width)\n",
        "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
        "\n",
        "    self.label_start = self.total_window_size - self.label_width\n",
        "    self.labels_slice = slice(self.label_start, None)\n",
        "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
        "\n",
        "  def __repr__(self):\n",
        "    return '\\n'.join([\n",
        "        f'Total window size: {self.total_window_size}',\n",
        "        f'Input indices: {self.input_indices}',\n",
        "        f'Label indices: {self.label_indices}',\n",
        "        f'Label column name(s): {self.label_columns}'])\n",
        "\n",
        "  def split_window(self, features):\n",
        "    inputs = features[:, self.input_slice, :]\n",
        "    labels = features[:, self.labels_slice, :]\n",
        "    if self.label_columns is not None:\n",
        "      labels = tf.stack(\n",
        "          [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
        "          axis=-1)\n",
        "\n",
        "    if self.input_columns is not None:\n",
        "      inputs = tf.stack(\n",
        "          [inputs[:, :, self.column_indices[name]] for name in self.input_columns],\n",
        "          axis=-1)\n",
        "  \n",
        "    # Slicing doesn't preserve static shape information, so set the shapes\n",
        "    # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
        "    inputs.set_shape([None, self.input_width, None])\n",
        "    labels.set_shape([None, self.label_width, None])\n",
        "  \n",
        "    return inputs, labels\n",
        "\n",
        "  def make_dataset(self, data):\n",
        "    data = np.array(data, dtype=np.float32)\n",
        "    ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "        data=data,\n",
        "        targets=None,\n",
        "        sequence_length=self.total_window_size,\n",
        "        sequence_stride=1,\n",
        "        shuffle=True,\n",
        "        batch_size=BATCH_SIZE,\n",
        "    )\n",
        "\n",
        "    ds = ds.map(self.split_window)\n",
        "\n",
        "    return ds\n",
        "  \n",
        "  @property\n",
        "  def train(self):\n",
        "    return self.make_dataset(self.train_df)\n",
        "  \n",
        "  @property\n",
        "  def val(self):\n",
        "    if not self.val_df:\n",
        "      return None\n",
        "      \n",
        "    return self.make_dataset(self.val_df)\n",
        "\n",
        "  @property\n",
        "  def test(self):\n",
        "    return self.make_dataset(self.test_df)\n",
        "  \n",
        "  @property\n",
        "  def example(self):\n",
        "    \"\"\"Get and cache an example batch of `inputs, labels` for plotting. \"\"\"\n",
        "    result = getattr(self, '_example', None)\n",
        "    if result is None:\n",
        "      # No example batch was found, so get from the `.train` dataset\"\"\"\n",
        "      result = next(iter(self.train))\n",
        "      # And cache it for next time\n",
        "      self._example = result\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7pUeQFq6QXo5"
      },
      "outputs": [],
      "source": [
        "# input_width: how far should the model look back\n",
        "# label_width: length of window to be predicted\n",
        "# shift: how further into future to be predicted (shift by 1, predicts next value, shift by 0 predicts last input index's value)\n",
        "\n",
        "# multivariate\n",
        "# window = WindowGenerator(WINDOW_SIZE, 1, 0, input_columns=[\"sector_id\", \"# of blocks\"], label_columns=[\"hot/cold\"])\n",
        "\n",
        "# univariate\n",
        "window = WindowGenerator(WINDOW_SIZE, 1, 0, input_columns=[\"sector_id\", \"time_delta\"], label_columns=[\"hot/cold\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.config.run_functions_eagerly(True)\n",
        "tf.data.experimental.enable_debug_mode()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "in user code:\n\n    File \"/tmp/ipykernel_80145/3125151173.py\", line 5, in helper  *\n        numpyTensor = features.numpy()\n\n    AttributeError: 'Tensor' object has no attribute 'numpy'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m/home/skele/Documents/PNU/grad/grad-project/src/model/lstm_model.ipynb Cell 30\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/skele/Documents/PNU/grad/grad-project/src/model/lstm_model.ipynb#X36sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39meager shit\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/skele/Documents/PNU/grad/grad-project/src/model/lstm_model.ipynb#X36sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m (addressToTensor(features[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mnumpy()), label)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/skele/Documents/PNU/grad/grad-project/src/model/lstm_model.ipynb#X36sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m encoded \u001b[39m=\u001b[39m testWindow\u001b[39m.\u001b[39;49mtrain\u001b[39m.\u001b[39;49mmap(helper)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/skele/Documents/PNU/grad/grad-project/src/model/lstm_model.ipynb#X36sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(encoded)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:2208\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2205\u001b[0m   \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m DEBUG_MODE:\n\u001b[1;32m   2206\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2207\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m`num_parallel_calls` argument is specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2208\u001b[0m   \u001b[39mreturn\u001b[39;00m MapDataset(\u001b[39mself\u001b[39;49m, map_func, preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   2209\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2210\u001b[0m   \u001b[39mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[1;32m   2211\u001b[0m       \u001b[39mself\u001b[39m,\n\u001b[1;32m   2212\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2215\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   2216\u001b[0m       name\u001b[39m=\u001b[39mname)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:5406\u001b[0m, in \u001b[0;36mMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5404\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_inter_op_parallelism \u001b[39m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m   5405\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality \u001b[39m=\u001b[39m preserve_cardinality\n\u001b[0;32m-> 5406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[1;32m   5407\u001b[0m     map_func,\n\u001b[1;32m   5408\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(),\n\u001b[1;32m   5409\u001b[0m     dataset\u001b[39m=\u001b[39;49minput_dataset,\n\u001b[1;32m   5410\u001b[0m     use_legacy_function\u001b[39m=\u001b[39;49muse_legacy_function)\n\u001b[1;32m   5411\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m name\n\u001b[1;32m   5412\u001b[0m variant_tensor \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39mmap_dataset(\n\u001b[1;32m   5413\u001b[0m     input_dataset\u001b[39m.\u001b[39m_variant_tensor,  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   5414\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39mfunction\u001b[39m.\u001b[39mcaptured_inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5417\u001b[0m     preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality,\n\u001b[1;32m   5418\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_common_args)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:261\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m defun_kwargs\u001b[39m.\u001b[39mupdate({\u001b[39m\"\u001b[39m\u001b[39m_tf_data_function\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m})\n\u001b[1;32m    260\u001b[0m \u001b[39mif\u001b[39;00m dataset_ops\u001b[39m.\u001b[39mDEBUG_MODE:\n\u001b[0;32m--> 261\u001b[0m   fn_factory \u001b[39m=\u001b[39m trace_py_function(defun_kwargs)\n\u001b[1;32m    262\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m   \u001b[39mif\u001b[39;00m def_function\u001b[39m.\u001b[39mfunctions_run_eagerly():\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:213\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_py_function\u001b[0;34m(defun_kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m   ret \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_tensor_list(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    211\u001b[0m   \u001b[39mreturn\u001b[39;00m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ret]\n\u001b[0;32m--> 213\u001b[0m _ \u001b[39m=\u001b[39m unused\u001b[39m.\u001b[39;49mget_concrete_function()\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpy_function_wrapper\u001b[39m(\u001b[39m*\u001b[39margs):\n\u001b[1;32m    216\u001b[0m   nested_args \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mfrom_compatible_tensor_list(\n\u001b[1;32m    217\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_structure, args)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2610\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2601\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   2602\u001b[0m   \u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m   2603\u001b[0m \n\u001b[1;32m   2604\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2608\u001b[0m \u001b[39m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m   2609\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2610\u001b[0m   graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\n\u001b[1;32m   2611\u001b[0m       \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2612\u001b[0m   graph_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   2613\u001b[0m   \u001b[39mreturn\u001b[39;00m graph_function\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2576\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2574\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2575\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m-> 2576\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m   2577\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m   2578\u001b[0m   captured \u001b[39m=\u001b[39m object_identity\u001b[39m.\u001b[39mObjectIdentitySet(\n\u001b[1;32m   2579\u001b[0m       graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39minternal_captures)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2758\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[1;32m   2759\u001b[0m   args, kwargs \u001b[39m=\u001b[39m placeholder_dict[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m-> 2760\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[1;32m   2762\u001b[0m graph_capture_container \u001b[39m=\u001b[39m graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   2763\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2665\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m   2666\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   2667\u001b[0m ]\n\u001b[1;32m   2668\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m   2669\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 2670\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m   2671\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m   2672\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m   2673\u001b[0m         args,\n\u001b[1;32m   2674\u001b[0m         kwargs,\n\u001b[1;32m   2675\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[1;32m   2676\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m   2677\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m   2678\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m   2679\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m   2680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m   2681\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m   2682\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   2683\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   2684\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   2685\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   2686\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   2687\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1245\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1247\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1249\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:209\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_py_function.<locals>.unused\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39m@eager_function\u001b[39m\u001b[39m.\u001b[39mdefun_with_attributes(\n\u001b[1;32m    204\u001b[0m     input_signature\u001b[39m=\u001b[39mstructure\u001b[39m.\u001b[39mget_flat_tensor_specs(\n\u001b[1;32m    205\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_structure),\n\u001b[1;32m    206\u001b[0m     autograph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    207\u001b[0m     attributes\u001b[39m=\u001b[39mdefun_kwargs)\n\u001b[1;32m    208\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munused\u001b[39m(\u001b[39m*\u001b[39margs):  \u001b[39m# pylint: disable=missing-docstring,unused-variable\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m   ret \u001b[39m=\u001b[39m wrapper_helper(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    210\u001b[0m   ret \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_tensor_list(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    211\u001b[0m   \u001b[39mreturn\u001b[39;00m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ret]\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:177\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    176\u001b[0m   nested_args \u001b[39m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 177\u001b[0m ret \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39;49mtf_convert(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func, ag_ctx)(\u001b[39m*\u001b[39;49mnested_args)\n\u001b[1;32m    178\u001b[0m \u001b[39mif\u001b[39;00m _should_pack(ret):\n\u001b[1;32m    179\u001b[0m   ret \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(ret)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 692\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m    693\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
            "File \u001b[0;32m/tmp/__autograph_generated_filemkno7fl3.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__helper\u001b[0;34m(features, label)\u001b[0m\n\u001b[1;32m      8\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 10\u001b[0m numpyTensor \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39;49mld(features)\u001b[39m.\u001b[39;49mnumpy, (), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state\u001b[39m():\n\u001b[1;32m     13\u001b[0m     \u001b[39mreturn\u001b[39;00m ()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:446\u001b[0m, in \u001b[0;36mTensor.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mT\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mravel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtranspose\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mclip\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msize\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    438\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtolist\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[1;32m    439\u001b[0m   \u001b[39m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001b[39;00m\n\u001b[1;32m    440\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m    441\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m    442\u001b[0m \u001b[39m    If you are looking for numpy-related methods, please run the following:\u001b[39m\n\u001b[1;32m    443\u001b[0m \u001b[39m    from tensorflow.python.ops.numpy_ops import np_config\u001b[39m\n\u001b[1;32m    444\u001b[0m \u001b[39m    np_config.enable_numpy_behavior()\u001b[39m\n\u001b[1;32m    445\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"\u001b[39m)\n\u001b[0;32m--> 446\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(name)\n",
            "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_80145/3125151173.py\", line 5, in helper  *\n        numpyTensor = features.numpy()\n\n    AttributeError: 'Tensor' object has no attribute 'numpy'\n"
          ]
        }
      ],
      "source": [
        "testWindow = WindowGenerator(WINDOW_SIZE, 1, 0,train_df=trainData[[\"sector_id\", \"hot/cold\"]][:10], input_columns=[\"sector_id\"], label_columns=[\"hot/cold\"])\n",
        "\n",
        "\n",
        "def helper(features, label):\n",
        "    numpyTensor = features.numpy()\n",
        "    if tf.executing_eagerly():\n",
        "        print(\"eager shit\")\n",
        "    print(numpyTensor)\n",
        "\n",
        "    return (addressToTensor(features[0].numpy()), label)\n",
        "encoded = testWindow.train.map(helper)\n",
        "print(encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUrOPTaoV1Ac"
      },
      "outputs": [],
      "source": [
        "# example_window = tf.stack([np.array(windowTrain[:window.total_window_size]),\n",
        "#                            np.array(windowTrain[100:100+window.total_window_size]),\n",
        "#                            np.array(windowTrain[200:200+window.total_window_size])])\n",
        "\n",
        "# example_inputs, example_labels = window.split_window(example_window)\n",
        "\n",
        "# print('All shapes are: (batch, time, features)')\n",
        "# print(f'Window shape: {example_window.shape}')\n",
        "# print(f'Inputs shape: {example_inputs.shape}')\n",
        "# print(f'Labels shape: {example_labels.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-3KvbalalFN",
        "outputId": "3d0c28c0-5a82-4fa1-d3af-966b94ea7650"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-09-05 17:52:25.697530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-05 17:52:25.838735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-05 17:52:25.839379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-05 17:52:25.842100: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-09-05 17:52:25.843369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-05 17:52:25.843955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-05 17:52:25.844351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-05 17:52:27.066117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-05 17:52:27.067049: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-05 17:52:27.067343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-05 17:52:27.067509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3381 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 960M, pci bus id: 0000:02:00.0, compute capability: 5.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape (batch, time, features): (256, 128, 2)\n",
            "Label shape (batch, time, features): (256, 128, 2)\n"
          ]
        }
      ],
      "source": [
        "print(f'Input shape (batch, time, features): {window.example[0].shape}')\n",
        "print(f'Label shape (batch, time, features): {window.example[0].shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQWIWUrP7xlI"
      },
      "outputs": [],
      "source": [
        "  # makeWindow([1,2,3,4,5,6], [2,3,4,5,6,7], windowLength=2, step=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9bcg0Az5l9i"
      },
      "outputs": [],
      "source": [
        "# windowedFeatures, windowedLabels = makeWindow(features,target, windowLength=100, step=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hz_HwPEZ5l9i"
      },
      "outputs": [],
      "source": [
        "# print(windowedFeatures[0])\n",
        "# print(windowedLabels[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYy0ysyc5l9i"
      },
      "source": [
        "### Model Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEzyYxz-841W"
      },
      "source": [
        "Normalization on features using tf.Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hn07OGEN5l9j"
      },
      "outputs": [],
      "source": [
        "# normalizationLayer = tf.keras.layers.Normalization(axis=None)\n",
        "# normalizationLayer.adapt(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIB_e_nK5l9j"
      },
      "outputs": [],
      "source": [
        "# normalizedTrainInput = normalizationLayer(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQtJAQt28-P4"
      },
      "source": [
        "Dataset of tensorflow,\n",
        "originally thinking of using it as a window splitter, however, implemented window by myself"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDSb_oNG5l9j"
      },
      "outputs": [],
      "source": [
        "# Note: I basically concluded that large sector_ids are not possible to embed(preprocess).\n",
        "# However, I thought of a way to represent sector_ids in tensors and that is one hot encoding and deep neural networks (aka. Dense, Fully connected)\n",
        "# It could be wrong and I want more research on \n",
        "#   **representing numbers in one-hot encoding and RNN**\n",
        "#   **Is it possible to feed LSTM large numbers**\n",
        "# also checkout tf.data.Dataset.grouping_window() and tf.data.Dataset.window() functions \n",
        "# i think they can be used to generate windows. gl\n",
        "\n",
        "# ds = tf.data.Dataset.from_tensor_slices((features, target))\n",
        "# ds = ds.window(10, shift=1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQUGXGsC5l9k"
      },
      "outputs": [],
      "source": [
        "# Operations on window\n",
        "# count = 0\n",
        "\n",
        "# def to_numpy(ds):\n",
        "#     return list(ds.as_numpy_iterator())\n",
        "\n",
        "# for window in ds:\n",
        "#     if count == 5:\n",
        "#         break\n",
        "#     count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XocSEPNq5l9k",
        "outputId": "1687a35d-6b67-408c-dca3-db1abc823eba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "maxSectorNumber: 1000213824\n",
            "maxBlocks: 2048\n"
          ]
        }
      ],
      "source": [
        "maxSectorNumber = np.amax(trainData[\"sector_id\"])\n",
        "maxBlocks = np.amax(trainData[\"# of blocks\"])\n",
        "print(\"maxSectorNumber:\", maxSectorNumber)\n",
        "print(\"maxBlocks:\", maxBlocks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p73wFi-15l9k",
        "outputId": "6601ae1f-088a-4d85-c70c-584206a7409e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J02zbKC95l9l"
      },
      "outputs": [],
      "source": [
        "# tensorTrainingData = []\n",
        "\n",
        "# for i in range(features.size):\n",
        "#     tensorTrainingData.append(addressToTensor(features[i]))\n",
        "\n",
        "# tensorTrainingData = tf.Variable(tensorTrainingData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2-kV4dM5l9l"
      },
      "outputs": [],
      "source": [
        "# tensorTestData = []\n",
        "\n",
        "# for i in range(10000):\n",
        "#     tensorTestData.append(addressToTensor(testFeatures[i]))\n",
        "\n",
        "# tensorTestData = tf.Variable(tensorTestData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3RbsxZohpMF"
      },
      "outputs": [],
      "source": [
        "# tensorTrainingData.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTRu9t1J5l9l",
        "outputId": "dda8fc06-e100-4462-dc19-d551bc2f212b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 128)]             0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 128, 256)          406195200 \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 128, 128)          197120    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128, 128)          0         \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 128, 1)           129       \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 406,392,449\n",
            "Trainable params: 406,392,449\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# embedding the sector number from 0-1\n",
        "# input_shape=(number of time steps, number of features)\n",
        "n_steps = WINDOW_SIZE\n",
        "n_features = 1\n",
        "\n",
        "embed_input = tf.keras.layers.Input(shape=(n_steps,))\n",
        "blocks_input = tf.keras.layers.Input(shape=(n_steps,))\n",
        "\n",
        "emb = tf.keras.layers.Embedding(input_dim=trainLabelSize, output_dim=256, input_length=n_steps)(embed_input)\n",
        "# emb = tf.keras.layers.Embedding(input_dim=trainLabelSize, output_dim=64, input_length=WINDOW_SIZE)(embed_input)\n",
        "# emb = tf.keras.layers.BatchNormalization()(emb)\n",
        "\n",
        "# conv1 = tf.keras.layers.Conv1D(filters=64, kernel_size=3, padding='same')(emb)\n",
        "# conv1 = tf.keras.layers.Activation('relu')(conv1)\n",
        "# conv1 = tf.keras.layers.BatchNormalization()(conv1)\n",
        "# conv1 = tf.keras.layers.MaxPooling1D(pool_size=2)(conv1)\n",
        "\n",
        "# conv2 = tf.keras.layers.Conv1D(filters=32, kernel_size=3, padding='same')(conv1)\n",
        "# conv2 = tf.keras.layers.Activation('relu')(conv2)\n",
        "# conv2 = tf.keras.layers.BatchNormalization()(conv2)\n",
        "# conv2 = tf.keras.layers.MaxPooling1D(pool_size=2)(conv2)\n",
        "\n",
        "lstm = tf.keras.layers.LSTM(128, return_sequences=True)(emb)\n",
        "dropout = tf.keras.layers.Dropout(0.1)(lstm)\n",
        "\n",
        "flatten = tf.keras.layers.Flatten()(dropout)\n",
        "conc = tf.keras.layers.Concatenate()([flatten, blocks_input])\n",
        "\n",
        "# out = tf.keras.layers.Dense(1, activation='sigmoid')(dropout)\n",
        "timeDistributed = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1, activation='sigmoid'))(conc)\n",
        "model = tf.keras.Model(inputs=(embed_input,blocks_input), outputs=timeDistributed)\n",
        "\n",
        "# model = tf.keras.Sequential()\n",
        "# model.add(tf.keras.layers.Embedding(input_dim=trainLabelSize, output_dim=64, input_length=WINDOW_SIZE))\n",
        "\n",
        "# model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'))\n",
        "# model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
        "\n",
        "# model.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "# model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
        "\n",
        "# model.add(tf.keras.layers.LSTM(128))\n",
        "# model.add(tf.keras.layers.Dropout(0.1))\n",
        "# model.add(tf.keras.layers.Dense(64,activation='relu'))\n",
        "# model.add(tf.keras.layers.Dropout(0.1))\n",
        "# model.add(tf.keras.layers.Dense(32,activation='relu'))\n",
        "# model.add(tf.keras.layers.Flatten())\n",
        "# model.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8--m0NtvkcU4"
      },
      "outputs": [],
      "source": [
        "MAX_EPOCHS = 5\n",
        "def compile_and_fit(model, window, patience=2, epochs=MAX_EPOCHS):\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping('loss', patience=patience, mode='min')\n",
        "\n",
        "  # model.compile(loss=tf.keras.losses.BinaryCrossentropy(), \n",
        "  #               optimizer=tf.keras.optimizers.Adam(clipnorm=0.1))\n",
        "\n",
        "  model.compile(loss=tf.keras.losses.BinaryCrossentropy(), \n",
        "                optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
        "  \n",
        "  def converter(features, labels):\n",
        "    '''used for multivariate input'''\n",
        "    return (features[:,:,0:1], features[:,:,1:2]), labels\n",
        "\n",
        "  # trainDataset = window.train.map(converter)\n",
        "\n",
        "  history = model.fit(window.train, epochs=epochs, \n",
        "                      callbacks=[early_stopping])\n",
        "\n",
        "  return history\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJti7Si6AjJn",
        "outputId": "ad60fec9-0d7f-442e-8c08-c76f14e2fa44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "37837/37837 [==============================] - 4198s 111ms/step - loss: 0.6761 - accuracy: 0.5732\n",
            "Epoch 2/5\n",
            "37837/37837 [==============================] - 4205s 111ms/step - loss: 0.6745 - accuracy: 0.5740\n",
            "Epoch 3/5\n",
            "37837/37837 [==============================] - 4213s 111ms/step - loss: 0.6739 - accuracy: 0.5743\n",
            "Epoch 4/5\n",
            "37837/37837 [==============================] - 4212s 111ms/step - loss: 0.6736 - accuracy: 0.5745\n",
            "Epoch 5/5\n",
            "37837/37837 [==============================] - 4212s 111ms/step - loss: 0.6734 - accuracy: 0.5746\n"
          ]
        }
      ],
      "source": [
        "history = compile_and_fit(model, window)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEO84m01OOZJ"
      },
      "source": [
        "### Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "objyAV3CLRQ2",
        "outputId": "7ee52160-4c81-4fff-c3e1-6f69c62d1ece"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!sudo pip install h5py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TpzNd6NKgYv",
        "outputId": "055cd061-c622-4595-ad8b-9e4b6ac9b5c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved\n"
          ]
        }
      ],
      "source": [
        "# Saving model to JSON file\n",
        "model_json = model.to_json()\n",
        "with open(\"drive/MyDrive/grad/models/functional/CNNLSTM10E.json\", \"w\") as json_file:\n",
        "  json_file.write(model_json)\n",
        "\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"drive/MyDrive/grad/models/functional/CNNLSTM10E.h5\")\n",
        "print(\"Model saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2KARnjrPyAI"
      },
      "source": [
        "### Load model and fit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2KcZnChP08x",
        "outputId": "a4465630-3105-49a1-d093-7a17ee32b0a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 128)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 128, 256)          406195200 \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 128, 128)          197120    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128, 128)          0         \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 128, 1)           129       \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 406,392,449\n",
            "Trainable params: 406,392,449\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "jsonFile = open(\"drive/MyDrive/grad/models/functional/CNNLSTM10E.json\", 'r')\n",
        "loadedJsonModel = jsonFile.read()\n",
        "jsonFile.close()\n",
        "\n",
        "loadedModel = model_from_json(loadedJsonModel)\n",
        "# load weights\n",
        "loadedModel.load_weights(\"drive/MyDrive/grad/models/functional/CNNLSTM10E.h5\")\n",
        "\n",
        "loadedModel.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-WCtAAWQvIR",
        "outputId": "4dfb5684-6239-4f05-a857-64564084733a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "37837/37837 [==============================] - 4751s 125ms/step - loss: 0.6733 - accuracy: 0.5746\n",
            "Epoch 2/5\n",
            " 6615/37837 [====>.........................] - ETA: 1:05:03 - loss: 0.6730 - accuracy: 0.5750"
          ]
        }
      ],
      "source": [
        "history = compile_and_fit(loadedModel, window)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4NKNrCiQ_kW"
      },
      "source": [
        "Save loaded model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BDJ7im4RBg8"
      },
      "outputs": [],
      "source": [
        "# Saving model to JSON file\n",
        "model_json = loadedModel.to_json()\n",
        "with open(\"drive/MyDrive/grad/models/functional/CNNLSTM10E.json\", \"w\") as json_file:\n",
        "  json_file.write(model_json)\n",
        "\n",
        "# serialize weights to HDF5\n",
        "loadedModel.save_weights(\"drive/MyDrive/grad/models/functional/CNNLSTM10E.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APp3JbhYLVDg"
      },
      "outputs": [],
      "source": [
        "# Stacked LSTM\n",
        "# reduced output dimension of embedding layer (experimenting)\n",
        "# deleted gradient clipping (gradient clipping could've been unnecessary)\n",
        "# running on two epochs\n",
        "\n",
        "# hyperparameters for experiment:\n",
        "#   - window size\n",
        "#   - learning_rate\n",
        "#   - dropout rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvQnCDn6wWQX"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n",
        "!pip show tensorflow\n",
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGtA7vO22gON"
      },
      "outputs": [],
      "source": [
        "history.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KG5NoLe_EYv6"
      },
      "outputs": [],
      "source": [
        "# def converter(features, labels):\n",
        "#   return (features[:,:,0:1], features[:,:,1:2]), labels\n",
        "\n",
        "# testDataset = window.test.map(converter)\n",
        "results = model.evaluate(window.test)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFcdWvCVLg_3"
      },
      "outputs": [],
      "source": [
        "def converter(features, labels):\n",
        "  return (features[:,:,0:1], features[:,:,1:2]), labels\n",
        "\n",
        "testDataset = window.test.map(converter)\n",
        "predictions = model.predict(window.test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulYIMY8IOcXq"
      },
      "outputs": [],
      "source": [
        "print(predictions.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqBssZ7ra0Ap"
      },
      "outputs": [],
      "source": [
        "idx = 0\n",
        "print(predictions[idx])\n",
        "print(testData[\"hot/cold\"][idx+WINDOW_SIZE -1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lY9R6kD6OxqV"
      },
      "outputs": [],
      "source": [
        "correct = 0\n",
        "pSize = predictions.size\n",
        "numberOfOnes = 0\n",
        "numberOfZeroes = 0\n",
        "wrong = 0\n",
        "\n",
        "for i in range(pSize):\n",
        "  if predictions[i][0] >= 0.5 and testData[\"hot/cold\"][i + WINDOW_SIZE - 1] == 1:\n",
        "    correct += 1\n",
        "    numberOfOnes += 1\n",
        "  elif predictions[i][0] < 0.5 and testData[\"hot/cold\"][i + WINDOW_SIZE - 1] == 0:\n",
        "    correct += 1\n",
        "    numberOfZeroes += 1\n",
        "  else:\n",
        "    wrong += 1\n",
        "\n",
        "print(\"Accuracy: \", correct / pSize)\n",
        "print(\"Ones: \", numberOfOnes)\n",
        "print(\"Zeroes: \", numberOfZeroes)\n",
        "print(\"Wrong: \", wrong)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKOxR1wutq_k"
      },
      "outputs": [],
      "source": [
        "mean = predictions.mean()\n",
        "print(\"mean: \", mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGm8kVhUPnNW"
      },
      "outputs": [],
      "source": [
        "!mkdir -p drive/MyDrive/grad/models/functional\n",
        "model.save('drive/MyDrive/grad/models/functional/cnnlstm_uni_batchnorm')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ-Q959b5DRS"
      },
      "source": [
        "Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPIS1Hn989w7"
      },
      "outputs": [],
      "source": [
        "predictions.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wB0FGO-K3-jB"
      },
      "outputs": [],
      "source": [
        "# the histogram of the data\n",
        "n, bins, patches = plt.hist(predictions, 150, density=True, facecolor='g', alpha=0.75)\n",
        "plt.xlabel('Probability')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Histogram of model prediction')\n",
        "plt.xlim(0, 1)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "By-8Seqm5l9m"
      },
      "outputs": [],
      "source": [
        "  #Optimizer \n",
        "# loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "# opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "# grads_and_vars = opt.compute_gradients(loss_fn)\n",
        "# model.compile(optimizer=opt, loss=\"mse\")\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sx6PIYdU5l9m"
      },
      "outputs": [],
      "source": [
        "#One hot encoded shit\n",
        "# train_x = np.asarray(tensorTrainingData)\n",
        "# test_x = np.asarray(tensorTestData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6DiSR2r8iF9"
      },
      "outputs": [],
      "source": [
        "# print(len(windowedFeatures))\n",
        "# print(len(target))\n",
        "\n",
        "# windowedFeatures.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1aWyrOU5l9m"
      },
      "outputs": [],
      "source": [
        "# model.fit(windowedFeatures[:10000], windowedLabels[:10000], epochs=1, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFVyTIvI5l9n"
      },
      "outputs": [],
      "source": [
        "# y_hat = model.predict(test_x, verbose=1)\n",
        "# y_hat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDBDKcyS5l9n"
      },
      "outputs": [],
      "source": [
        "# correct = 0\n",
        "# for i in range(10000):\n",
        "#     if y_hat[i] == testTarget[i]:\n",
        "#         correct += 1\n",
        "\n",
        "# print(f\"Accuracy: {correct/10000}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
